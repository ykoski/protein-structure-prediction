{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Protein secondary structure prediction using bidirectional LSTM networks</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 1. Introduction </h2>\n",
    "\n",
    "Proteins are large biomolecules that can be found in all biological organisms. They have a vast array of biological functions e.g. DNA replication, responding to stimuli and catalysing metabolic reactions. Proteins consist of amino acid chains called polypeptides. The folded form of a polypeptide is called the secondary structure of a protein. These folded polypeptides can bind together to from the tertiary structure of a protein. In total there are 20 different standard amino acids. The amino acids in the polypeptide chains interact with each other and form a secondary structure which is a three-dimensional structure that sets the proteins function. For example the secondary structure can be a binding site for a specific biomolecule which can catalyze the reaction of said molecule.\n",
    "\n",
    "It has been a huge interest in biochemical research to find a way to predict the secondary structure of an amino acid chain. If the secondary structure could be predicted it would be possible to engineer proteins for specific reactions. This would revolutionize the enzyme industry since we could create custom catalytes for different chemical reactions. However, the prediction is not an easy task. There has been a variety of methods that have been used to solve this problem in the past sixty-five years. In the past decade deep learning models have been performing very well. [1]\n",
    "\n",
    "In this project I'm applying a bidirectional Long-short-term memory on a dataset that has information about secondary structures of amino acid sequences. In general obtaining such data is slow and expensive. This is due to the nature of methods used to get protein features including X-ray and Nuclear Magnetic Resonance. In addition to the industrial uses of the structure prediction it can also be used to get a better understanding of the functions of a cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def to_categorical(y, num_classes):\n",
    "    # 1-hot encodes a tensor\n",
    "    out = np.eye(num_classes, dtype='uint8')[y]\n",
    "    return torch.from_numpy(out).long()\n",
    "\n",
    "def sequence_to_ngram(seqs, n = 3):\n",
    "    # Creates n-grams of length n for sequences in seqs\n",
    "    ngrams = np.array([[seq[i:i+n] for i in range(len(seq))] for seq in seqs])\n",
    "    return ngrams\n",
    "\n",
    "def pad_tensors(seqs, targets, seq_dict, target_dict, context_size):\n",
    "    # Adds padding to both sequence and target tensors\n",
    "    # Padding value is 0 and all tensors are padded to the length of the longest\n",
    "    # Tensor in the group i.e. if maxlen is 32 all tensors will have length 32.\n",
    "    \n",
    "    tensors = []\n",
    "    goal_tensors = []\n",
    "    for i in range(len(seqs)):\n",
    "        seq_tensor = torch.tensor([seq_dict[x] for x in seqs[i]], dtype = torch.long)\n",
    "        goal_tensor = torch.tensor([target_dict[y] for x in targets[i] for y in x], dtype = torch.long)\n",
    "        tensors.append(seq_tensor)\n",
    "        goal_tensor = to_categorical(goal_tensor, context_size)\n",
    "        goal_tensors.append(goal_tensor)\n",
    "    padded_seqs = pad_sequence(tensors, batch_first = True)\n",
    "    goal_tensors = pad_sequence(goal_tensors, batch_first = True)\n",
    "    return padded_seqs, goal_tensors\n",
    "\n",
    "def fix_ones(target):\n",
    "    # This is used to add 1s to resemble the padding values\n",
    "    # So that the model will learn to find the end of sequence\n",
    "    for row in target:\n",
    "        if max(row) == 0:\n",
    "            row[0] = 1\n",
    "    return target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 2. Data </h2>\n",
    "\n",
    "The data is protein secondary structure data from the RCBS Protein Data Bank (https://www.rcsb.org/). The dataset that I used was hosted at Kaggle: https://www.kaggle.com/alfrandom/protein-secondary-structure. These protein structures are obtained with X-ray or NMR methods which find the 3D coordinates of each atoms in the molecule. These can be used to solve the 3D structure of the protein.\n",
    "\n",
    "The protein structure can be modeled by using eight different structure types or states provided by DSSP software [2]. Each amino acid is assigned to one of the eight structure types so that the structural sequences are of equal length as the amino acid sequences. The eight structure types are:\n",
    "\n",
    "<h3> Q8 model </h3>\n",
    "1. **C**: Loops and irregular elements\n",
    "2. **E**: β-strand\n",
    "3. **H**: α-helix\n",
    "4. **B**: β-bridge\n",
    "5. **G**: 3-helix\n",
    "6. **I**: π-helix\n",
    "7. **T**: Turn\n",
    "8. **S**: Bend\n",
    "\n",
    "It is common to group some of the structure types for more simple prediction. We can group these eight states to three states:\n",
    "\n",
    "<h3> Q3 model </h3>\n",
    "1. **E**: E and B\n",
    "2. **H**: H, G and I\n",
    "3. **C**: C, S and T\n",
    "\n",
    "The dataset has 7 columns: *pbd_id* (Unique identifier for a protein sequence), *chain_code* (Used to locate a certain peptide in a case where protein consists of multiple peptides), *seq* (Amino acid sequence), *sst8* (Q8 structure of the sequence), *sst3* (Q3 structure of the sequence), *len* (length of the sequence) and *has_nonstd_aa* (Boolean wether the protein sequence has non-standard amino acids.\n",
    "\n",
    "These values are used to filter the data and as the actual features. The goal is to predict either *sst3* or *sst8* from *seq*. The sequences are filtered by *len* and *has_nonstd_aa*. I trained the model for Q3 and Q8 structure types for two different lengths: smaller than 32 and smaller than 128. Sequences with nonstd amino acids were always discarded.\n",
    "\n",
    "Here is a small description of the data. The figure shows the distribution of sequence lengths and the red line is the length cutoff used for this project:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  pdb_id chain_code  seq sst8 sst3  len  has_nonstd_aa\n",
      "0   1A30          C  EDL  CBC  CEC    3          False\n",
      "1   1B05          B  KCK  CBC  CEC    3          False\n",
      "2   1B0H          B  KAK  CBC  CEC    3          False\n",
      "3   1B1H          B  KFK  CBC  CEC    3          False\n",
      "4   1B2H          B  KAK  CBC  CEC    3          False\n",
      "Max length: 5037, Minimum length: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x7f971a188358>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/2018-06-06-ss.cleaned.csv\")\n",
    "\n",
    "# Describring and visualizing the data\n",
    "\n",
    "print(df.head())\n",
    "print(f\"Max length: {max(df.len)}, Minimum length: {min(df.len)}\")\n",
    "\n",
    "df.pdb_id.describe()\n",
    "\n",
    "# Maximum sequence length can be 32 (small set) or 128 (larger set)\n",
    "max_len = 32\n",
    "#max_len = 128\n",
    "\n",
    "df.len.hist(bins = 100)\n",
    "plt.axvline(x=max_len, color='r', linestyle='dashed', linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 2.1 Preprocessing </h3>\n",
    "\n",
    "To increase the vocabulary size and to get a better understanding of how the amino acids are generally ordered in the sequences I use n-grams. N-grams have been widely used in biological context for different sequence data from 80s to modern day [3,4]. I use n-grams of length 3 which can be formulated in the following way:\n",
    "\n",
    "$Ngram(S_a) = S_a + S_{a+1} + S_{a+2}$\n",
    "\n",
    "where $S$ is the amino acid sequence and $a$ is an index of an amino acid. If $a+1 \\mbox{ or } a+2  > \\mbox{len(S)} \\ , \\ S_{a+1} = \\emptyset$ \n",
    "\n",
    "By doing this for all the sequences we can increase the vocabulary size from 20 to 8420. This will increase the prediction accuracy significantly.\n",
    "\n",
    "The filtered data is split into test and train sets and the size of the test set is 20% of the size of the whole dataset. \n",
    "\n",
    "A dictionary for the amino acid triplets and for the structural states has to be created to be able to feed the data into a network. The sequences are represented as a tensor of integers and the structure as a one-hot coded matrix of size: $\\mbox{sequence length} \\times \\mbox{categories + 1}$.\n",
    "\n",
    "The tensors are padded with zeros so that they are of equal length. In this case the max length is either 32 or 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "7838\n"
     ]
    }
   ],
   "source": [
    "# States variable decides if the three-state or eight-state model will be used\n",
    "\n",
    "states = 'sst3'\n",
    "#states = 'sst8'\n",
    "\n",
    "# Context size is amount of states + 1 because of the padding value\n",
    "if states == 'sst3':\n",
    "    context_size = 4\n",
    "elif states == 'sst8':\n",
    "    context_size = 9\n",
    "\n",
    "# Filter the dataframe to get only seqs smaller than maxlen and remove seqs with nonstd aminoacids\n",
    "input_seqs, target_seqs = df[['seq', states]][(df.len <= max_len) & (~df.has_nonstd_aa)].values.T\n",
    "\n",
    "# Expand the sequence corpus by applying a sliding overlapping window\n",
    "ngrams = sequence_to_ngram(input_seqs)\n",
    "\n",
    "# Set up sequence and target dictionaries\n",
    "\n",
    "seq_dict = {}\n",
    "count = 1\n",
    "for i in ngrams:\n",
    "    for j in i:\n",
    "        if j not in seq_dict.keys():\n",
    "            seq_dict[j] = count\n",
    "            count += 1\n",
    "\n",
    "c = 1\n",
    "target_dict = {}\n",
    "for i in target_seqs:\n",
    "    for j in i:\n",
    "        if j not in target_dict.keys():\n",
    "            target_dict[j] = c\n",
    "            c += 1\n",
    "\n",
    "# Split into test and train\n",
    "seq_train, seq_test, target_train, target_test = train_test_split(ngrams, target_seqs, \n",
    "                                                                  test_size = 0.2, random_state = 0)\n",
    "# Save the original input seqs with same partition for later\n",
    "input_train, input_test, _, _ = train_test_split(input_seqs, target_seqs, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Create padded tensors\n",
    "seq_train, target_train = pad_tensors(seq_train, target_train, seq_dict, target_dict, context_size)\n",
    "seq_test, target_test = pad_tensors(seq_test, target_test, seq_dict, target_dict, context_size)\n",
    "\n",
    "# See the amount of states and amount of amino acid triplets in out dataset\n",
    "print(len(target_dict))\n",
    "print(len(seq_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 3. Models </h2>\n",
    "\n",
    "For this task I chose to use Long short term memory (LSTM) network since it works well with sequential data. Since the sequence data is not typical natural language data and the relationships between the aminoacids should be concidered in both directions I chose to use a Bidirectional LSTM. Bidirectional-LSTM is very similar to a normal LSTM. Instead of using only past features it uses also the future features. [5]\n",
    "\n",
    "The network architecture used is as follows (left side is tensor shape and right side is a function applied between layers):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](bi-LSTM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function I used was Categorical Cross-Entropy Loss which is widely used loss function for multiclass classification. I tried the model with different hyperparameters and the best results came with following combination:\n",
    "- Learning rate: 0.05\n",
    "- Embedding_dim: max_length of sequences\n",
    "- Hidden_dim: max_lengt of sequences\n",
    "\n",
    "In total I used four different models:\n",
    "1. Short sequences (max_len = 32) with three-state structure\n",
    "2. Long sequences (max_len = 128) with three-state structure\n",
    "3. Short sequences (max_len = 32) with eigth-state structure\n",
    "4. Long sequences (max_len = 128) with eigth-state structure\n",
    "\n",
    "Out of these models the three-state models have been used previously for this problem but the eight-state model has not. It is interesting to see which factors have the largest effect on the results.\n",
    "\n",
    "These models were trained with the whole train-set. Training used 10 epochs with batch size 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network model\n",
    "class NGramModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, context_size):\n",
    "        super(NGramModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)  # Embed the input sequence\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2, bidirectional = True, num_layers = 1) # Bidirectional LSTM layer\n",
    "        self.dropout = nn.Dropout(0.1) # Dropout of the LSTM layer\n",
    "        self.lin = nn.Linear(hidden_dim, context_size) # Linear layer to map output to context_size dimensions\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embedding(inputs)\n",
    "        out, states = self.lstm(embeds.view(1, len(inputs), -1))\n",
    "        out = self.dropout(out)\n",
    "        out = self.lin(out.view(1,len(inputs), -1))\n",
    "        out = F.log_softmax(out, dim = 2)\n",
    "        out = out.view(len(inputs),-1)\n",
    "        return(out)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.05\n",
    "vocab_size = len(seq_dict) + 1\n",
    "\n",
    "losses = []\n",
    "loss_f = nn.CrossEntropyLoss()\n",
    "model = NGramModel(max_len, max_len, vocab_size, context_size)\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "if training == True:\n",
    "    for epoch in range(10):\n",
    "        total_loss = 0\n",
    "        i = 0\n",
    "        print(f\"Starting epoch number {epoch}\")\n",
    "        for seq in seq_train:\n",
    "            model.zero_grad()\n",
    "            log_probs = model(seq)\n",
    "\n",
    "            target = target_train[i]\n",
    "            target = fix_ones(target)\n",
    "\n",
    "            loss = loss_f(log_probs, torch.max(target,1)[1])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            i += 1\n",
    "\n",
    "            if i % 10000 == 0:\n",
    "                print(f\"epoch: {epoch} , i: {i}\")\n",
    "        print(total_loss)\n",
    "        losses.append(total_loss)\n",
    "    print(losses)\n",
    "    #torch.save(\"test_model.pth\")\n",
    "else:\n",
    "    # Load the model that fits the state and maxlen values\n",
    "    if max_len == 32 and states == 'sst3':\n",
    "        model = torch.load(\"LSTM_model_proper_3_state_small.pth\")\n",
    "    elif max_len == 32 and states =='sst8':\n",
    "        model = torch.load(\"LSTM_model_proper_8_state_small.pth\")\n",
    "    elif max_len == 128 and states == 'sst3':\n",
    "        model = torch.load(\"LSTM_model_proper.pth\")\n",
    "    elif max_len == 128 and states == 'sst8':\n",
    "        model = torch.load(\"LSTM_model_proper_8_state.pth\")\n",
    "    else:\n",
    "        pass\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 4. Results </h2>\n",
    "\n",
    "Here are the prediction accuracies for the four models described above. \n",
    "\n",
    "| Model        | Prediction accuracy (test) | Prediction accuracy (train)  |\n",
    "| ------------ |:--------------------------:| ----------------------------:|\n",
    "| Model 1      |                      0.786 |                        0.794 |\n",
    "| Model 2      |                      0.690 |                        0.697 |\n",
    "| Model 3      |                      0.624 |                        0.625 |\n",
    "| Model 4      |                      0.501 |                        0.500 |\n",
    "\n",
    "Belove are visualizations of comparisons between actual structure and predicted structure for five examples using model 1 on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Input:      ETREQRAIRLARMSAYAARRLAN\n",
      "Target:     CCHHHHHHHHHCCCCCCCCCCCC\n",
      "Prediction: CCCHCHCCHHCCCCHCCCHHCCC\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n",
      "---\n",
      "Input:      GHRP\n",
      "Target:     CECC\n",
      "Prediction: CECC\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "---\n",
      "Input:      FVNQHLCGSHLVEALYLVCGERGFFYTPKT\n",
      "Target:     CCCECCCCHHHHHHHHHHHHHHCEEECCCC\n",
      "Prediction: CCCHCCCCHHHHHHHHHHHHHHCEEECCCC\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96875\n",
      "---\n",
      "Input:      DGVFTTPCDPEYAGG\n",
      "Target:     CCCCCCCCCCCCCCC\n",
      "Prediction: CCCCECCCCCHCCCC\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9375\n",
      "---\n",
      "Input:      FVNQHLCGSHLVEALYLVCGERGFFYTPKT\n",
      "Target:     CECCCCCCCCCCCCEECCCCCCCCCCCCCC\n",
      "Prediction: CCCHCCCCHHHHHHHHHHHHHHCEEECCCC\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk4AAABoCAYAAAAHM3/3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAACHVJREFUeJzt3V+IXGcdxvHncZM1YaO0YZdY2k3UongRakyGglBNFStqL2pBYgtCe7W5UIiYC4MXtQpiECNeCG1WLI2gxmJbDVTFQktsCKnN1o1pGuwfSWjTNH8oxQaKf9rHizkJS8zuvM2ckzO7+X5gyZyzJ+/8+PHO7MN53511EgEAAKC3d7VdAAAAwHxBcAIAAChEcAIAAChEcAIAAChEcAIAAChEcAIAAChEcAIAAChEcAIAAChEcAIAACi0qKmBR0dHs2rVyqaGBwAA89wbp060XcI5z7/0yukkY72uayw4rVq1Uvv27mlqeAAAMM/t3r6t7RLOuWnTXUdLrmOpDgAAoBDBCQAAoBDBCQAAoBDBCQAAoBDBCQAAoBDBCQAAoBDBCQAAoFCtwcn2hO39tvefPnW6zqEBAABaV2twSjKZpJOkMzo2WufQAAAArWOpDgAAoBDBCQAAoBDBCQAAoBDBCQAAoBDBCQAAoBDBCQAAoJCTNDLwe5cuy/XXru5rjC0TN9dSy9bJR/oeY/3E5hoqkXZPbqtlnIWkrt6iOVs21vNarMPW7f2/ntGsOt7nFtr7Au/9F/aHqcfaLuGc4SUjU0k6va7jjhMAAEAhghMAAEAhghMAAEAhghMAAEAhghMAAEChouBk+322d9p+0faU7d/b/nDTxQEAAAySRb0usG1JD0vakeS26txHJa2Q9Fyz5QEAAAyOnsFJ0qck/SfJvWdPJDnQXEkAAACDqSQ4rZY0VTKY7QlJE5K0ZPFwH2UBAAAMnlo3hyeZTNJJ0lk8tLjOoQEAAFpXEpwOSVrXdCEAAACDriQ4PSbp3dUynCTJ9nW2P9FcWQAAAIOnZ3BK968A3yrpM9XHERyS9H1JrzZdHAAAwCAp2RyuJK9I2tBwLQAAAAONTw4HAAAoRHACAAAoRHACAAAo5O7e7/qtW7c2+/bu6WuMrdsfqaWWLRtvrmUc4HJV12uxDryeLw+7t29ru4Rard+4ue0S0MPwkpGpJJ1e13HHCQAAoBDBCQAAoBDBCQAAoBDBCQAAoFDRB2DafkvSwRmndibZ2kxJAAAAg6koOEl6M8maRisBAAAYcCzVAQAAFCoNTkttT8/4+nKjVQEAAAygWpfqbE9ImpCklePj/dQFAAAwcGpdqksymaSTpDM6Nlrn0AAAAK1jjxMAAECh0qW6pbanZxz/McmWJgoCAAAYVEXBKclQ04UAAAAMOpbqAAAAChGcAAAAChGcAAAACjlJIwOvW7c2+/buaWTsNuzevq2WcdZv3FzLOAtJXb0FMBh4n8N8NLxkZCpJp9d13HECAAAoRHACAAAoRHACAAAoRHACAAAoRHACAAAo1DM42T5z3vGdtn/SXEkAAACDiTtOAAAAhQhOAAAAhUr+yO9S29MzjpdL2nWhC21PSJqQpJXj4/1XBwAAMEBK7ji9mWTN2S9Jd812YZLJJJ0kndGx0fqqBAAAGAAs1QEAABQiOAEAABQiOAEAABTquTk8ybLzju+XdH9D9QAAAAws7jgBAAAUIjgBAAAUIjgBAAAUcpJmBrZPSTo6xyWjkk438uSQ6G+T6G1z6G1z6G1z6G2zLlV/VyUZ63VRY8Gp5xPb+5N0WnnyywD9bQ69bQ69bQ69bQ69bdag9ZelOgAAgEIEJwAAgEJtBqfJFp/7ckB/m0Nvm0Nvm0Nvm0NvmzVQ/W1tjxMAAMB8w1IdAABAoVaCk+3P2f677Rdsb2mjhoXK9hHbB21P297fdj3zne37bJ+0/cyMc8ttP2r7+erfK9uscb6apbd32z5Wzd9p219os8b5yva47cdtP2v7kO1N1Xnmbp/m6C1zt0+2l9j+i+0DVW+/U53/gO0nq8zwa9vDrdZ5qZfqbA9Jek7STZJelvSUpNuTPHtJC1mgbB+R1EnCZ4rUwPYnJZ2R9PMkq6tzP5D0WpKtVfC/Msk326xzPpqlt3dLOpPkh23WNt/ZvkrSVUmetv0eSVOSvijpTjF3+zJHbzeIudsX25Y0kuSM7cWS9kjaJOkbkh5KstP2vZIOJLmnrTrbuON0vaQXkvwjyb8l7ZR0Swt1AD0l+bOk1847fYukHdXjHeq+aeIdmqW3qEGS40merh6/IemwpKvF3O3bHL1Fn9J1pjpcXH1F0qcl/aY63/q8bSM4XS3ppRnHL4tJV6dI+pPtKdsTbRezQK1Icrx6/KqkFW0WswB9zfbfqqU8lpL6ZPv9kj4m6Ukxd2t1Xm8l5m7fbA/ZnpZ0UtKjkl6U9HqS/1aXtJ4Z2By+8NyQZK2kz0v6arUcgoaku9bNr6bW5x5J10paI+m4pG3tljO/2V4m6UFJX0/yz5nfY+725wK9Ze7WIMlbSdZIukbdFaqPtFzS/2kjOB2TND7j+JrqHGqQ5Fj170lJD6s78VCvE9U+h7P7HU62XM+CkeRE9cb5tqSfivl70ao9Ig9K+kWSh6rTzN0aXKi3zN16JXld0uOSPi7pCtuLqm+1nhnaCE5PSfpQtUt+WNJtkna1UMeCY3uk2qwo2yOSPivpmbn/Fy7CLkl3VI/vkPS7FmtZUM7+UK/cKubvRak22f5M0uEkP5rxLeZun2brLXO3f7bHbF9RPV6q7i+RHVY3QH2puqz1edvKB2BWv6b5Y0lDku5L8r1LXsQCZPuD6t5lkqRFkn5Jb/tj+1eSblT3r3OfkPRtSb+V9ICklZKOStqQhE3O79Asvb1R3aWOSDoiaeOMPTkoZPsGSU9IOijp7er0t9Tdi8Pc7cMcvb1dzN2+2L5O3c3fQ+re2HkgyXern207JS2X9FdJX0nyr9bq5JPDAQAAyrA5HAAAoBDBCQAAoBDBCQAAoBDBCQAAoBDBCQAAoBDBCQAAoBDBCQAAoBDBCQAAoND/AII/iaklT1h3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.40625\n",
      "Mean prediction accuracy (test): 0.7860973428985734\n",
      "Mean prediction accuracy (train): 0.7939385325828787\n"
     ]
    }
   ],
   "source": [
    "# Dicts used to convert category values to sequence or state values\n",
    "rev_seq_dict = {value:key for key, value in seq_dict.items()}\n",
    "rev_target_dict = {value:key for key, value in target_dict.items()}\n",
    "\n",
    "def pred_to_onehot(pred):\n",
    "    # Turns the category probability matrix into onehot\n",
    "    out = np.zeros_like(pred)\n",
    "    out[np.arange(len(pred)), pred.argmax(1)] = 1\n",
    "    return out\n",
    "\n",
    "def onehot_to_seq(onehot_seq, index_dict):\n",
    "    # Truens the onehot matrix into predicted structure sequence\n",
    "    seq = ''\n",
    "    for o in onehot_seq:\n",
    "        max_i = np.argmax(o)\n",
    "        if max_i != 0:\n",
    "            seq += index_dict[max_i]\n",
    "        else:\n",
    "            break\n",
    "    return seq\n",
    "\n",
    "def plot_results(x, y, y_):\n",
    "    # Plots the comparison between actual structure and the predicted structure\n",
    "    # Predicted structure is orange and actual structure blue\n",
    "    # If the blue and orange overlap it means that prediction == actual for that amino acid\n",
    "    # The upmost value means sequence end\n",
    "    print(\"---\")\n",
    "    print(\"Input:      \" + str(x))\n",
    "    print(\"Target:     \" + str(onehot_to_seq(y, rev_target_dict).upper()))\n",
    "    print(\"Prediction: \" + str(onehot_to_seq(y_, rev_target_dict).upper()))\n",
    "    fig = plt.figure(figsize=(10,2))\n",
    "    plt.imshow(y.T, cmap='Blues')\n",
    "    plt.imshow(y_.T, cmap='Oranges', alpha=.5)\n",
    "    plt.yticks(range(4), [' '] + [rev_target_dict[i+1].upper() for i in range(3)])\n",
    "    plt.show()\n",
    "\n",
    "def full_accuracy(test, target):\n",
    "    # Counts the full test accuracy for the whole test set\n",
    "    accuracies = []\n",
    "    for i in range(len(test)):\n",
    "        outputs = model(test[i])\n",
    "        pred = pred_to_onehot(outputs.detach().numpy())\n",
    "        pred = np.argmax(pred,1)\n",
    "        actual = np.argmax(target[i],1).numpy()\n",
    "        pred = pred[pred != 0]\n",
    "        actual = actual[actual != 0]\n",
    "        acc = accuracy_score(pred, actual)\n",
    "        accuracies.append(acc)\n",
    "    return np.mean(accuracies)\n",
    "\n",
    "# Amount of examples to be visualized\n",
    "n = 5\n",
    "\n",
    "test = seq_test[:n]\n",
    "i_test = input_test[:n]\n",
    "target = target_test[:n]\n",
    "\n",
    "mean_acc = 0\n",
    "\n",
    "for i in range(len(test)):\n",
    "    outputs = model(test[i])\n",
    "    pred = pred_to_onehot(outputs.detach().numpy())\n",
    "    plot_results(input_test[i], target[i].numpy(), pred)\n",
    "    pred = np.argmax(pred,1)\n",
    "    actual = np.argmax(target[i],1).numpy()\n",
    "    acc = accuracy_score(pred, actual)\n",
    "    print(f'Accuracy: {acc}')\n",
    "    mean_acc += acc\n",
    "\n",
    "mean_acc = mean_acc / (i+1)\n",
    "print(f'Mean prediction accuracy (test): {full_accuracy(seq_test, target_test)}')\n",
    "print(f'Mean prediction accuracy (train): {full_accuracy(seq_train, target_train)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 5. Discussion </h2>\n",
    "\n",
    "The model with smaller sequence length and less states performed the best and the model with higher sequence length and more states performed the worst. By looking at the results we can see that both increasing sequence length and increasing possible states made the prediction more difficult. It seems like increasing the sequence length had a bit higher impact than increasing amount of states.\n",
    "\n",
    "In comparison to another implementation of similar network my network performed a bit worse. The other implementation had test accuracy of 0.8679 for model similar to my model 1. [6]\n",
    "\n",
    "By comparing the test and train accuracies we can see that there is little difference. It seems like there was little to none overfitting. \n",
    "\n",
    "Models that I used performed decently compared to the best ones around. Further steps to improve would be to make a more complicated network structure that could be able to learn the features even better and to improve the hyperparameter estimation.\n",
    "\n",
    "Protein secondary structure prediction remains as an interesting and difficult topic in computational biology. It is interesting to see how much the prediction accuracy will increase in the future while even better methods are developed. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> References </h2>\n",
    "\n",
    "[1] Yang, Yuedong et al. “Sixty-five years of the long march in protein secondary structure prediction: the final stretch?.” Briefings in bioinformatics vol. 19,3 (): 482-494. doi:10.1093/bib/bbw129\n",
    "\n",
    "[2] Wouter G Touw, Coos Baakman, Jon Black, Tim AH te Beek, E Krieger, Robbie P Joosten, Gert Vriend.: A series of PDB related databases for everyday needs.\n",
    "Nucleic Acids Research 2015 January; 43(Database issue): D364-D368. https://swift.cmbi.umcn.nl/gv/dssp/index.html\n",
    "\n",
    "[3] Erhan, S & Marzolf, T & Cohen, L. (1980). Amino-acid neighborhood relationships in proteins. Breakdown of amino-acid sequences into overlapping doublets, triplets and quadruplets. International journal of bio-medical computing. 11. 67-75. 10.1016/0020-7101(80)90007-0. \n",
    "\n",
    "[4] Coin L, Bateman A, Durbin R. Enhanced protein domain discovery by using\n",
    "language modeling techniques from speech recognition. Proc Natl Acad Sci USA 2003; 100: 4516-20\n",
    "\n",
    "[5] Z. Huang, W. Xu, and K. Yu.  Bidirectional LSTM-CRF models for sequence tagging. CoRR,abs/1508.01991, 2015.\n",
    "\n",
    "[6] https://www.kaggle.com/helmehelmuto/u-nets-are-the-shit\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
